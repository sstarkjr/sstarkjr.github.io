---
title: 'Extracting Insights from Reviews: A Step-by-Step Data Processing Workflow
Introduction'
date: 2025-01-20
permalink: /posts/2025/10/blog-post-2/
tags:
  - text embedding
  - category1
---

# Introduction

Understanding customer feedback requires both clarity and interaction. Below is a visualization of "key phrases" generated by a Large Language Model. These key phrases are integral in the beginning of a topic analysis exercise. Unstructured product reviews are rich in user commentary and simple review analysis doesn't provide meaningful or actionable insights. By visualizing key phrases you can start to see patterns in the things that people are talking about. I'll save the clustering approac for another blog post. For now, feel free to explore the interactive visual below -- try zooming in and out or hovering over the individual points.

<iframe src="/images/key-phrase-embedings.html" width="1000" height="1000" frameborder="0"></iframe>

The problem with unstructured review text is that it can be difficult to analyze in a systematic way. Traditional quantitative analysis tells only half the story (arguably less...). This challenge is complicated by the size of most modern day review datasets. Reviews often cover multiple topics (both positive and negative) in a single review. Therefore it is important to be as granular as possible for parsing these separate topics and to do it in a scalable way that handles the size of a large reviews dataset.

I started with an Amazon reviews dataset provided by []. I filtered down to reviews for only a single product, the Cuisinart Coffee Maker, Single Serve 72-Ounce Reservoir Coffee Machine, Programmable Brewing & Hot Water Dispenser, Stainless Steel, SS-10P1,Silver. I sampled down to 2,000 random unique reviews due to OpenAI cost limitations. With a larger budget, this is not required.

#TODO insert quant measure of reviews

With that done, I turned to OpenAI to help generate key phrases. I took inspiration for this approach from this article [reference article]

I used this prompt.

Here is a screenshot of a couple reviews demonstrating how it works.

I then took these key phrases and expanded the dataframe to separate rows and generated text embeddings for each review. I then used UMAP projection for dimensionality reduction. I did this so I can generate a graphic representation of the text embeddings.

Here is the visual. Note, this is interactive. A few interesting clusters that are obvious that I want to explore further in a follow-up clustering analysis.
- Error code
- general product praise
- Comparisons to Keurig
- Lighting issues

# Conclusion
Summarize key takeaways: How each step contributes to meaningful insights.
Encourage readers to experiment with similar workflows and stay tuned for the clustering post.
Technical Tips and Insights
Add any lessons learned or optimizations you made during this project (e.g., handling LLM API rate limits, embedding size considerations).


1. Aggregate & filter data as needed
2. Generate key-phrases from the reviews using batch prediction LLM call
3. Parse the results. Add to datafrae. Expand each key-phrase to be it's own row. 
4. Generate text embeddings.
5. Dimensionality Reduction using UMAP.
6. Visual Confirmation of patterns
7. Clustering Methods (next post)

# Citations
@article{hou2024bridging,
  title={Bridging Language and Items for Retrieval and Recommendation},
  author={Hou, Yupeng and Li, Jiacheng and He, Zhankui and Yan, An and Chen, Xiusi and McAuley, Julian},
  journal={arXiv preprint arXiv:2403.03952},
  year={2024}
}