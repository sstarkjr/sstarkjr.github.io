---
title: 'Extracting Insights from Reviews: A Step-by-Step Data Processing Workflow
Introduction'
date: 2025-05-01
permalink: /posts/2025/05/blog-post-2/
tags:
  - text embedding
  - category1
---

# Introduction
Understanding customer feedback is a classic analytics challenge. The qualitative side is just as important as the quantitative -- but much harder to process at scale. Product reviews are rich with insight, serving a range of stakeholders: *consumers* looking to make decisions, *product designers* hunting for feedback, and *marketers* seeking to better understand how people talk about the product.

But at some point, the sheer volume becomes overwhelming. How do you programmatically analyze thousands of reviews?

To tackle this, I break down each review into a set of key phrases using a large language model. In my prompt, I define a key phrase as a short, standalone snippet that captures one salient idea, theme, or sentiment. In practice, this has worked extremely well to tease out the multiple distinct ideas often embedded in a single review.

For this example, I chose a publicly available dataset of Amazon reviews for the Cuisinart SS-10P1 Single Serve Coffee Maker. It‚Äôs a product I know well. It has thousands of reviews and many features, it‚Äôs ideal for digging through rich customer feedback.

Tools used: Python, OpenAI API, UMAP, Plotly


# Step 1: Gather and Clean the Review Data
The dataset comes from the Amazon open review collection. I filtered down to just the reviews for one product using the ASIN: [INSERT_ASIN_HERE].

Modern LLMs require minimal text cleaning. The main steps I included:
- de-duplicated data
- removed nulls

‚û°Ô∏è [Insert code block or diagram of your initial dataframe structure]

# Step 2: Extract Key Phrases with an LLM
To extract key phrases, I sent the reviews through a batch LLM pipeline. My prompt was simple but effective:

> *‚ÄúAnalyze the following product review. Analyze each text string, identifying key phrases that capture the most salient themes and topics.‚Äù
You will be provided with product review details, and you will output a json object containing the following information:
```json
{
    key_phrases: string[] // Array of key phrases from the product review,
    summary: string // 1-sentence summary of the product review
}
```    
  ** Product Review Details: **
  Review Title: {review_title} \n
  Review Text: {review_text}
  Star Rating (out of 5 stars): {rating}

  **Note:**
  * Rely only on the product review provided to you and not your general knowledge.
  * Always answer honestly and truthfully.*
* 

Batching was essential here. Processing 2,500 reviews one-by-one would take \~17,500 seconds at 7s/review. With batch predictions, the same job ran in \~1,800 seconds‚Äîa 90% speedup.

üß∫ To conceptualize batching, I use the laundry machine analogy: doing one load at a time is slow; multiple machines running in parallel finishes the job much faster.  

Once results came back, I parsed them into a dataframe and exploded each key phrase into its own row.

‚û°Ô∏è [Insert code snippet showing prompt, batch call, and parsing output]

# Step 3: Generate Embeddings for Key Phrases
With the key phrases extracted, I generated vector embeddings for each one using text-embedding-3-small from OpenAI. Each phrase was transformed into a 500-dimensional vector.

Text embeddings let us numerically represent the semantic meaning of each phrase. This is the bridge between messy natural language and structured mathematical representation.

‚û°Ô∏è [Insert code for generating embeddings]

# 5. Step 4: Dimensionality Reduction with UMAP
To visualize the embeddings, I needed to reduce them from 500 dimensions down to just 2. For this, I used UMAP (Uniform Manifold Approximation and Projection).

UMAP works well for this type of semantic data‚Äîpreserving both local and global structure in the vector space.
‚û°Ô∏è [Optional: insert UMAP configuration notes or image showing 2D projection]

# 6. Step 5: Visualize in 2D
Using Plotly, I created an interactive 2D scatterplot where each point is a key phrase. You can zoom, hover, and explore natural groupings of semantically similar ideas.

Some clusters are immediately obvious‚Äîphrases about temperature, cleaning, or single-serve use tend to group together. This step alone surfaces themes that were buried across hundreds of individual reviews.

‚û°Ô∏è [Insert interactive plot or GIF of hover/zoom behavior]
<!-- Optional: label dense clusters manually or with a tool -->

7. Conclusion
This pipeline takes raw review text and transforms it into a structured, explorable format using:

LLM-powered key phrase extraction

Text embeddings to capture meaning

UMAP to visualize patterns in 2D

It opens the door to deeper insight without manually reading every review. From here, you could:

Apply clustering to label dense regions

Track how certain topics trend over time

Compare themes across different product variants

üîú In my next post, I‚Äôll explore how to cluster and automatically label these groups to uncover even more insight.



Below is a visualization of "key phrases" generated by a Large Language Model. These key phrases are integral in the beginning of a topic analysis exercise. Unstructured product reviews are rich in user commentary and simple review analysis doesn't provide meaningful or actionable insights. By visualizing key phrases you can start to see patterns in the things that people are talking about. I'll save the clustering approac for another blog post. For now, feel free to explore the interactive visual below -- try zooming in and out or hovering over the individual points.

<iframe src="/images/key-phrase-embedings.html" width="1000" height="1000" frameborder="0"></iframe>

The problem with unstructured review text is that it can be difficult to analyze in a systematic way. Traditional quantitative analysis tells only half the story (arguably less...). This challenge is complicated by the size of most modern day review datasets. Reviews often cover multiple topics (both positive and negative) in a single review. Therefore it is important to be as granular as possible for parsing these separate topics and to do it in a scalable way that handles the size of a large reviews dataset.

I started with an Amazon reviews dataset provided by []. I filtered down to reviews for only a single product, the Cuisinart Coffee Maker, Single Serve 72-Ounce Reservoir Coffee Machine, Programmable Brewing & Hot Water Dispenser, Stainless Steel, SS-10P1,Silver. I sampled down to 2,000 random unique reviews due to OpenAI cost limitations. With a larger budget, this is not required.

#TODO insert quant measure of reviews

With that done, I turned to OpenAI to help generate key phrases. I took inspiration for this approach from this article [reference article]

I used this prompt.

Here is a screenshot of a couple reviews demonstrating how it works.

I then took these key phrases and expanded the dataframe to separate rows and generated text embeddings for each review. I then used UMAP projection for dimensionality reduction. I did this so I can generate a graphic representation of the text embeddings.

Here is the visual. Note, this is interactive. A few interesting clusters that are obvious that I want to explore further in a follow-up clustering analysis.
- Error code
- general product praise
- Comparisons to Keurig
- Lighting issues

# Conclusion
Summarize key takeaways: How each step contributes to meaningful insights.
Encourage readers to experiment with similar workflows and stay tuned for the clustering post.
Technical Tips and Insights
Add any lessons learned or optimizations you made during this project (e.g., handling LLM API rate limits, embedding size considerations).


1. Aggregate & filter data as needed
2. Generate key-phrases from the reviews using batch prediction LLM call
3. Parse the results. Add to datafrae. Expand each key-phrase to be it's own row. 
4. Generate text embeddings.
5. Dimensionality Reduction using UMAP.
6. Visual Confirmation of patterns
7. Clustering Methods (next post)

# Citations
@article{hou2024bridging,
  title={Bridging Language and Items for Retrieval and Recommendation},
  author={Hou, Yupeng and Li, Jiacheng and He, Zhankui and Yan, An and Chen, Xiusi and McAuley, Julian},
  journal={arXiv preprint arXiv:2403.03952},
  year={2024}
}