---
title: "Question-Answering with OpenAI Vector Store"
date: 2025-09-03
permalink: /posts/2025/09/document-q-and-a/
tags: [vector-store, openai, rag, nlp, experimentation]

---

## Exploring OpenAI’s Vector Store with Congressional Data

I recently experimented with OpenAI’s new vector store capability by uploading a structured PDF document — the *Official Alphabetical List of the House of Representatives (119th Congress)*. This file contains every Representative, their state and district, and their committee assignments. You can find the official file on the [House Clerk’s website](https://clerk.house.gov/committee_info/oal.pdf).

Using the code in my notebook, I ingested the document into a vector store and then tested it with a set of natural language questions. Here are five example questions I used to test retrieval across different dimensions — from individual lookups to committee intersections:

1. **Which committees does Lauren Boebert serve on?**  
   *Answer: Natural Resources; Oversight and Government Reform.*

2. **List all Representatives who are on the Oversight and Government Reform Committee.**  
   *Answer: Includes members such as James Comer (Chair), Nancy Mace, Lauren Boebert, Raja Krishnamoorthi, among many others.*

3. **Which members serve on both the Armed Services Committee and the Veterans’ Affairs Committee?**  
   *Answer: Includes members such as Jack Bergman (MI-1) and Jennifer Kiggans (VA-2).*

4. **Who represents the 12th district of Georgia, and what committees do they serve on?**  
   *Answer: Rick W. Allen, serving on the Education and Workforce Committee and the Energy and Commerce Committee.*

5. **Who is the Chair of the Agriculture Committee?**  
   *Answer: Glenn Thompson (PA-15).*

These kinds of questions test retrieval in different ways: single lookups, cross-referencing committee memberships, geographic queries (district/state), and leadership roles.

What I found most interesting was how the vector store could surface relevant chunks of the document even though it wasn’t originally designed for easy search. Instead of scrolling through a PDF or relying on keyword search, I could ask open-ended questions and receive structured, context-aware answers.

This simple experiment highlights how retrieval-augmented generation (RAG) can transform static reference documents into interactive knowledge sources. Even a dense congressional roster becomes something you can query naturally, without manual scanning or keyword hunting.

---

## Try it yourself

If you’d like to experiment with this yourself, here’s a minimal Python example using the [OpenAI Python SDK](https://github.com/openai/openai-python).  
Make sure you have your `OPENAI_API_KEY` stored as an environment variable and that the file *oal.pdf* is in your working directory.

```python
from openai import OpenAI
import os

# Initialize client
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

# Step 1: Create a vector store
vs = client.vector_stores.create(name="house_representatives")

# Step 2: Upload the PDF
with open("oal.pdf", "rb") as f:
    client.vector_stores.file_batches.upload_and_poll(
        vector_store_id=vs.id,
        files=[f]
    )

# Step 3: Create an assistant with file search enabled
assistant = client.beta.assistants.create(
    name="Congress Q&A",
    instructions="Answer questions about the House of Representatives list.",
    model="gpt-4.1",
    tools=[{"type": "file_search"}],
    tool_resources={"file_search": {"vector_store_ids": [vs.id]}}
)

# Step 4: Ask a question
thread = client.beta.threads.create(messages=[
    {"role": "user", "content": "Who is the Chair of the Agriculture Committee?"}
])

run = client.beta.threads.runs.create_and_poll(
    thread_id=thread.id,
    assistant_id=assistant.id
)

# Step 5: Print the answer
messages = client.beta.threads.messages.list(thread_id=thread.id)
for m in messages.data:
    print(m.role, ":", m.content[0].text.value)
````
